import nltk
from nltk.tokenize import word_tokenize

nltk.download('punkt')
nltk.download('maxent_ne_chunker')
nltk.download('words')
nltk.download('maxent_ne_chunker')
nltk.download('maxent_ne_chunker')

def stochastic_pos_tagging(sentence):
    words = word_tokenize(sentence)
    pos_tags = nltk.pos_tag(words)
    return pos_tags

sentence1 = "The red car stopped at the traffic light."
sentence2 = "She quickly ran to catch the bus."

pos_tags1 = stochastic_pos_tagging(sentence1)
pos_tags2 = stochastic_pos_tagging(sentence2)

print("Sentence 1: " + sentence1)
print("Stochastic Part-of-Speech Tags 1:")
print(pos_tags1)

print("\nSentence 2: " + sentence2)
print("Stochastic Part-of-Speech Tags 2:")
print(pos_tags2)
